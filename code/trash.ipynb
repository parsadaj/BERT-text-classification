{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from transformers import AutoConfig, AutoTokenizer, TFAutoModel\n",
    "# from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(r'F:\\Daneshgah\\Arshad\\2_4002\\NLP\\HW5\\data\\persica.csv_train_x.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'وزير علوم  جمع استادان نمونه كشور گفت  استادان نمونه كشور انتظار مي رود كه رويكرد دانايي محوري  گفتمان علمي  عنوان يك بحث فرهنگي  دانشگاهها توسعه  رونق بخشند  گزارش سرويس صنفي آموزشي خبرگزاري دانشجويان ايران  ايسنا  دكتر محمد مهدي زاهدي  اولين مجمع عمومي استادان نمونه دانشگاه هاي سراسر كشور كه  دانشگاه تهران برگزار شد  افزود  توصيه ما  جهت تلاش براي دانايي محوري  توسعه گفتمان علمي  معني عدم تمايل  مباحث سياسي نيست  بلكه برعكس  دانشگاه بايد مهد چالشهاي گفتماني باشد ولي اين امر  بدان معني نيست كه دانشگاه  ابزار دست سياسيون قرار بگيرد  وي تأكيد كرد  دانشگاه نه تنها نبايد تحت تأثير القائات سياسي قرار بگيرد  بلكه بايد خط دهنده  برنامه ريز جريانات سياسي باشد  مهمترين عنصر پياده شدن اين آرمان  دانشجويان  اعضاي هيات علمي دانشگاهها  رأس آنها استادان نمونه هستند  وزير علوم  ذكر اين نكته كه  جامعه اطلاعاتي نمي توان هيچ تفكري  تهديد  ارعاب حاكم كرد  افزود  اگر چه دانشگاهها بايد پرچمدار كرسيهاي آزاد انديشي  حاكميت دانايي محوري باشند  بايد توجه داشته باشند كه ناخودآگاه تحت تأثير جوسازيها  القائات رسانه  قرار نگيرند  دكتر زاهدي سپس  اقدامات انجام شده  جهت ارتقاي جايگاه استادان نمونه اشاره كرد  گفت  بنياد نخبگان  استادان نمونه  مصاديق نخبگان شناخته شدند  اين امر  لحاظ معنوي  اهميت ويژهاي دارد  شوراي عالي انقلاب فرهنگي نيز براي اعضاي هيأت علمي  مرتبه علمي  استاد تمامي  بويژه استادان نمونه تسهيلات مناسبي  نظر گرفته شده كه اميدوارم بزودي تصويب شود  وي افزود  همچنين قرار است  تصويب  هيأت امناي دانشگاهها  افزايش سن بازنشستگي استادان نمونه  65  70 سال  دانشگاهها بتوانند  توان  ظرفيت علمي استادان نمونه  حداكثر استفاده  بكنند  وزير علوم  ادامه سپس  استادان نمونه خواست  تعريف  تعيين شاخصهاي لازم براي انتخاب  استاد نمونه  بازنگري كنند  توان استادان  ترويج فرهنگ علمي  دانشگاه  كنار توان آموزشي  پژوهشي آنان  عنوان يك شاخص  نظر بگيرند  دكتر زاهدي  پايان قول داد كه مشاوره  راهنماييها كه  اطاق فكر استادان نمونه بيرون بيايد  وسواس  دقت  تصميم گيريها لحاظ شود'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a[1].split():\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.load(r'F:\\Daneshgah\\Arshad\\2_4002\\NLP\\HW5\\data\\persica.csv_train_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8911"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8911"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tf_model.h5: 100%|██████████| 919M/919M [06:39<00:00, 2.41MB/s]  \n",
      "Some layers from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\", cache_dir=r'F:\\Daneshgah\\Arshad\\2_4002\\NLP\\HW5\\cache')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\", cache_dir=r'F:\\Daneshgah\\Arshad\\2_4002\\NLP\\HW5\\cache')\n",
    "model = TFAutoModel.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\", cache_dir=r'F:\\Daneshgah\\Arshad\\2_4002\\NLP\\HW5\\cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000000000000019884624838653"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tknz['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2179, 2028, 3637, 2963, 10517, 2037, 3485, 5371, 2338, 331, 4801, 300, 2440, 2698, 56916, 1196, 70899, 64066, 70899, 1212, 60257, 1212, 3247, 2036, 6559, 3831, 2383, 2362, 15, 4972, 2179, 3637, 8101, 2073, 2440, 2045, 15, 4], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "text = \"ما در هوشواره معتقدیم با انتقال صحیح دانش و آگاهی، همه افراد dfg sgdf sgf sadf  می‌توانند از ابزارهای هوشمند استفاده کنند. شعار ما هوش مصنوعی برای همه است.\"\n",
    "tknz = tokenizer(text, max_length=39, truncation=True)\n",
    "tknz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tknz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "k1 = 25\n",
    "k2 = 4\n",
    "a = np.arange(k).reshape((k1, k2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-230352956d6d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-230352956d6d>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    import numpy as a.n\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as a.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing pachages...\n"
     ]
    }
   ],
   "source": [
    "print('Importing pachages...')\n",
    "\n",
    "import sys\n",
    "from utils import *\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoConfig, AutoTokenizer, TFAutoModel\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "\n",
    "HW_path = Path(r'F:\\Daneshgah\\Arshad\\2_4002\\NLP\\HW5')\n",
    "\n",
    "data_folder = HW_path / 'data'\n",
    "results_folder = HW_path / 'results'\n",
    "\n",
    "cache_dir = HW_path / 'cache'\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(data_folder / 'persica.csv_train_x.npy', allow_pickle=True)[:100].tolist()\n",
    "y_train = np.load(data_folder / 'persica.csv_train_y.npy')[:100].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0dfa0bf71378>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_encodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(x_train, truncation=True, padding=True, max_length=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    y_train\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = dict(train_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(4715,), dtype=int32, numpy=array([   2, 2031, 2248, ...,    0,    0,    0])>,\n",
       " 'token_type_ids': <tf.Tensor: shape=(4715,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0])>,\n",
       " 'attention_mask': <tf.Tensor: shape=(4715,), dtype=int32, numpy=array([1, 1, 1, ..., 0, 0, 0])>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'تاريخي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'اجتماعي\\n',\n",
       " 'آموزشي\\n',\n",
       " 'اجتماعي\\n']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xd8\\xa2\\xd9\\x85\\xd9\\x88\\xd8\\xb2\\xd8\\xb4\\xd9\\x8a\\n'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ss['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4715"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ss['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9331"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Data...\n"
     ]
    }
   ],
   "source": [
    "## Data\n",
    "print('Importing Data...')\n",
    "\n",
    "x_train = np.load(data_folder / 'persica.csv_train_x.npy', allow_pickle=True).tolist()\n",
    "y_train = np.load(data_folder / 'persica.csv_train_y.npy').tolist()\n",
    "x_test = np.load(data_folder / 'persica.csv_test_x.npy', allow_pickle=True).tolist()\n",
    "y_test = np.load(data_folder / 'persica.csv_test_y.npy').tolist()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\", cache_dir=cache_dir)\n",
    "max_length = 9331 #max([len(tokenizer.tokenize(x)) for x in x_train]) + 2\n",
    "\n",
    "train_encodings = tokenizer(x_train, truncation=True, padding=True, max_length=max_length)\n",
    "val_encodings = tokenizer(x_val, truncation=True, padding=True, max_length=max_length)\n",
    "test_encodings = tokenizer(x_test, truncation=True, padding=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-bbd5aa835185>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_encodings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\YAHOO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YAHOO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YAHOO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-3>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YAHOO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YAHOO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YAHOO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    392\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                                 \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                             \u001b[1;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YAHOO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    y_train\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=1, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = np.linalg.svd(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 25), (4,), (4, 4))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape, s.shape, vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19],\n",
       "       [20, 21, 22, 23],\n",
       "       [24, 25, 26, 27],\n",
       "       [28, 29, 30, 31],\n",
       "       [32, 33, 34, 35],\n",
       "       [36, 37, 38, 39],\n",
       "       [40, 41, 42, 43],\n",
       "       [44, 45, 46, 47],\n",
       "       [48, 49, 50, 51],\n",
       "       [52, 53, 54, 55],\n",
       "       [56, 57, 58, 59],\n",
       "       [60, 61, 62, 63],\n",
       "       [64, 65, 66, 67],\n",
       "       [68, 69, 70, 71],\n",
       "       [72, 73, 74, 75],\n",
       "       [76, 77, 78, 79],\n",
       "       [80, 81, 82, 83],\n",
       "       [84, 85, 86, 87],\n",
       "       [88, 89, 90, 91],\n",
       "       [92, 93, 94, 95],\n",
       "       [96, 97, 98, 99]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.12544698e-17, 1.00000000e+00, 2.00000000e+00, 3.00000000e+00],\n",
       "       [4.00000000e+00, 5.00000000e+00, 6.00000000e+00, 7.00000000e+00],\n",
       "       [8.00000000e+00, 9.00000000e+00, 1.00000000e+01, 1.10000000e+01],\n",
       "       [1.20000000e+01, 1.30000000e+01, 1.40000000e+01, 1.50000000e+01],\n",
       "       [1.60000000e+01, 1.70000000e+01, 1.80000000e+01, 1.90000000e+01],\n",
       "       [2.00000000e+01, 2.10000000e+01, 2.20000000e+01, 2.30000000e+01],\n",
       "       [2.40000000e+01, 2.50000000e+01, 2.60000000e+01, 2.70000000e+01],\n",
       "       [2.80000000e+01, 2.90000000e+01, 3.00000000e+01, 3.10000000e+01],\n",
       "       [3.20000000e+01, 3.30000000e+01, 3.40000000e+01, 3.50000000e+01],\n",
       "       [3.60000000e+01, 3.70000000e+01, 3.80000000e+01, 3.90000000e+01],\n",
       "       [4.00000000e+01, 4.10000000e+01, 4.20000000e+01, 4.30000000e+01],\n",
       "       [4.40000000e+01, 4.50000000e+01, 4.60000000e+01, 4.70000000e+01],\n",
       "       [4.80000000e+01, 4.90000000e+01, 5.00000000e+01, 5.10000000e+01],\n",
       "       [5.20000000e+01, 5.30000000e+01, 5.40000000e+01, 5.50000000e+01],\n",
       "       [5.60000000e+01, 5.70000000e+01, 5.80000000e+01, 5.90000000e+01],\n",
       "       [6.00000000e+01, 6.10000000e+01, 6.20000000e+01, 6.30000000e+01],\n",
       "       [6.40000000e+01, 6.50000000e+01, 6.60000000e+01, 6.70000000e+01],\n",
       "       [6.80000000e+01, 6.90000000e+01, 7.00000000e+01, 7.10000000e+01],\n",
       "       [7.20000000e+01, 7.30000000e+01, 7.40000000e+01, 7.50000000e+01],\n",
       "       [7.60000000e+01, 7.70000000e+01, 7.80000000e+01, 7.90000000e+01],\n",
       "       [8.00000000e+01, 8.10000000e+01, 8.20000000e+01, 8.30000000e+01],\n",
       "       [8.40000000e+01, 8.50000000e+01, 8.60000000e+01, 8.70000000e+01],\n",
       "       [8.80000000e+01, 8.90000000e+01, 9.00000000e+01, 9.10000000e+01],\n",
       "       [9.20000000e+01, 9.30000000e+01, 9.40000000e+01, 9.50000000e+01],\n",
       "       [9.60000000e+01, 9.70000000e+01, 9.80000000e+01, 9.90000000e+01]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[:, :len(s)] @ np.diag(s) @ vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict(r=2,b=3)\n",
    "c = [i for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 'b']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sdfkl3esdf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3\n",
    "f'sdfkl{i}esdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open('/Users/parsa/Daneshgah/Arshad/2/NLP/Homeworks/HW4/index_to_label') as fp:\n",
    "        a = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\": \"\\\\u0622\\\\u0645\\\\u0648\\\\u0632\\\\u0634\\\\u064a\\\\n\", \"1\": \"\\\\u0627\\\\u062c\\\\u062a\\\\u0645\\\\u0627\\\\u0639\\\\u064a\\\\n\", \"2\": \"\\\\u062a\\\\u0627\\\\u0631\\\\u064a\\\\u062e\\\\u064a\\\\n\", \"3\": \"\\\\u0627\\\\u0642\\\\u062a\\\\u0635\\\\u0627\\\\u062f\\\\u064a\\\\n\", \"4\": \"\\\\u0628\\\\u0647\\\\u062f\\\\u0627\\\\u0634\\\\u062a\\\\u064a\\\\n\", \"5\": \"\\\\u0639\\\\u0644\\\\u0645\\\\u064a\\\\n\", \"6\": \"\\\\u0633\\\\u064a\\\\u0627\\\\u0633\\\\u064a\\\\n\", \"7\": \"\\\\u0641\\\\u0631\\\\u0647\\\\u0646\\\\u06af\\\\u064a\\\\n\", \"8\": \"\\\\u0641\\\\u0642\\\\u0647 \\\\u0648 \\\\u062d\\\\u0642\\\\u0648\\\\u0642\\\\n\", \"9\": \"\\\\u0645\\\\u0630\\\\u0647\\\\u0628\\\\u064a\\\\n\", \"10\": \"\\\\u0648\\\\u0631\\\\u0632\\\\u0634\\\\u064a\\\\n\"}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'آموزشي\\n',\n",
       " '1': 'اجتماعي\\n',\n",
       " '2': 'تاريخي\\n',\n",
       " '3': 'اقتصادي\\n',\n",
       " '4': 'بهداشتي\\n',\n",
       " '5': 'علمي\\n',\n",
       " '6': 'سياسي\\n',\n",
       " '7': 'فرهنگي\\n',\n",
       " '8': 'فقه و حقوق\\n',\n",
       " '9': 'مذهبي\\n',\n",
       " '10': 'ورزشي\\n'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10a9c6917087c897a5c02b1b09a0ff199f1a9b727d3906f0f1087811b9f3f37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
